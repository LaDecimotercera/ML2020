{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1  1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " ...\n",
      " [ 1  1  1  1  1]\n",
      " [-1 -1 -1 -1  1]\n",
      " [ 1  1  1  1  1]]\n",
      "[-1 -1 -1 ...  1 -1  1]\n",
      "[[0.00758676 0.00931677 0.03252033 0.00227716 0.01078619]\n",
      " [0.31388013 0.19277108 0.20408163 0.57425743 0.31810491]\n",
      " [0.06501548 0.33870968 0.28205128 0.10497238 0.26195029]\n",
      " ...\n",
      " [0.83018868 0.82894737 0.76       0.96       0.83443709]\n",
      " [0.         0.         0.13333333 0.01342282 0.88888889]\n",
      " [0.82191781 0.79564033 0.7027027  0.8440367  0.69130435]]\n",
      "[0.01249744 0.32061904 0.21053982 ... 0.84271463 0.20712901 0.77112038]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class RandomForest:\n",
    "    \n",
    "    def __init__(self, n_estimators):\n",
    "        self.base = []\n",
    "        self.n_estimators = n_estimators\n",
    "    \n",
    "    def bootstrap_sample(self, X, y):\n",
    "        len = X.shape[0]\n",
    "        y = y.reshape(len,1)\n",
    "        X_y = np.hstack((X,y))\n",
    "        np.random.shuffle(X_y)\n",
    "        \n",
    "        dataset = []\n",
    "        for t in range(self.n_estimators):\n",
    "            idm = np.random.choice(len, len, replace=True) # 有放回\n",
    "            bootstrap_X_y = X_y[idm,:]\n",
    "            bootstrap_X =  bootstrap_X_y[:,:-1]\n",
    "            bootstrap_y =  bootstrap_X_y[:,-1:]\n",
    "            dataset.append([bootstrap_X,bootstrap_y])\n",
    "        return dataset\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # 自助采样\n",
    "        sample = self.bootstrap_sample(X, y)\n",
    "        for t in range(self.n_estimators):\n",
    "            X_sub, y_sub = sample[t]\n",
    "            clf = DecisionTreeClassifier(max_features=\"log2\", ccp_alpha=0.0001)\n",
    "            clf.fit(X_sub, y_sub)\n",
    "            self.base.append(clf)    \n",
    "        return\n",
    "                \n",
    "    def predict(self, X):\n",
    "        m = X.shape[0]\n",
    "        votes = np.zeros((m, self.n_estimators)).astype(int)\n",
    "        for j in range(self.n_estimators):\n",
    "            votes[:,j] = self.base[j].predict(X)\n",
    "        print(votes)    \n",
    "        y_pred = np.zeros(m).astype(int)\n",
    "        for i in range(m):\n",
    "            (values,counts) = np.unique(votes[i, :],return_counts=True)\n",
    "            y_pred[i] = values[counts.argmax()]\n",
    "        print(y_pred)\n",
    "        #return y_pred\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        m = X.shape[0]\n",
    "        votes = np.zeros((m, self.n_estimators))\n",
    "        for j in range(len(self.base)):\n",
    "            votes[:,j] = self.base[j].predict_proba(X)[:,1]\n",
    "        print(votes)\n",
    "        prob = np.zeros(m)\n",
    "        for i in range(m):\n",
    "            prob[i] = votes[i, :].sum()/self.n_estimators\n",
    "        print(prob)\n",
    "        #return prob\n",
    "    \n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)     \n",
    "     \n",
    "\n",
    "def crossValidation(X, y):\n",
    "    kf = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    for t in range(1, 10):# test n_estimators\n",
    "        AUC = 0\n",
    "        #acc = 0\n",
    "        for train_index, val_index in kf.split(X,y):\n",
    "            train_data, val_data = X[train_index], X[val_index]\n",
    "            train_label, val_label = y[train_index], y[val_index]\n",
    "            clf = AdaBoost(n_estimators=t)\n",
    "            clf.fit(train_data,train_label)\n",
    "            pred = clf.predict(val_data)\n",
    "            prob = clf.predict_proba(val_data)\n",
    "            fp_rate, tp_rate, thresholds = roc_curve(val_label, prob)\n",
    "            AUC += auc(fp_rate, tp_rate)#roc_auc_score(val_label, pred)\n",
    "            #acc += accuracy_score(val_label, pred)\n",
    "        AUC /= 5\n",
    "        #val_acc /= 5\n",
    "        #y.append(val_AUC)\n",
    "        print(\"NUM = \",t,\" Valiadtion AUC = \", AUC)\n",
    "       #print(\"NUM = \", NUM ,\" Validation acc = \", val_acc)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    # load data from source\n",
    "    X_train = np.genfromtxt(\"adult_dataset/adult_train_feature.txt\")\n",
    "    X_test  = np.genfromtxt(\"adult_dataset/adult_test_feature.txt\")\n",
    "    y_train = np.genfromtxt(\"adult_dataset/adult_train_label.txt\")\n",
    "    y_test  = np.genfromtxt(\"adult_dataset/adult_test_label.txt\")\n",
    "    # preprocess\n",
    "    y_train = (y_train - 0.5) * 2\n",
    "    y_test = (y_test - 0.5) * 2\n",
    "    # train & predict\n",
    "    clf = RandomForest(n_estimators = 5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    clf.predict(X_test)\n",
    "    clf.predict_proba(X_test)\n",
    "    #print(clf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
